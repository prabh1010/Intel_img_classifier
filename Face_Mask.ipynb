{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Mask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabh1010/Intel_img_classifier/blob/main/Face_Mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAFOrYNvl25o"
      },
      "source": [
        "##**Uploading Folder Structure**##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9GKrdQNYcUL",
        "outputId": "186f15b5-5df2-4ab8-c2b8-df35e9fe6ce5"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDvkRS9QpZxS",
        "outputId": "f67f6522-bac6-4d7a-f1a6-77c997a0a0e0"
      },
      "source": [
        "#https://drive.google.com/file/d/1ET3PetGuG_cE8Hrgd4rqjuyyOO9jT2rw/view?usp=sharing\n",
        "!gdown https://drive.google.com/uc?id=1ET3PetGuG_cE8Hrgd4rqjuyyOO9jT2rw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ET3PetGuG_cE8Hrgd4rqjuyyOO9jT2rw\n",
            "To: /content/face.zip\n",
            "\r  0% 0.00/11.1k [00:00<?, ?B/s]\r100% 11.1k/11.1k [00:00<00:00, 19.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcEGSumepbbm",
        "outputId": "2aca8f94-191b-4404-c428-e4c712f7906b"
      },
      "source": [
        "!unzip face.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  face.zip\n",
            "   creating: content/training_demo/\n",
            "   creating: content/training_demo/pre-trained-models/\n",
            "   creating: content/training_demo/annotations/\n",
            "   creating: content/training_demo/exported-models/\n",
            "  inflating: content/training_demo/generate_tfrecord.py  \n",
            "  inflating: content/training_demo/export_tflite_graph_tf2.py  \n",
            "   creating: content/training_demo/.ipynb_checkpoints/\n",
            "   creating: content/training_demo/models/\n",
            "   creating: content/training_demo/images/\n",
            "   creating: content/training_demo/images/.ipynb_checkpoints/\n",
            "   creating: content/training_demo/images/train/\n",
            "   creating: content/training_demo/images/test/\n",
            "  inflating: content/training_demo/model_main_tf2.py  \n",
            "  inflating: content/training_demo/exporter_main_v2.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__qzHfcRmeeJ"
      },
      "source": [
        "##**Uploading Saved Checkpoints**\n",
        " (we've trained the model earlier...to continue from same pt.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6khChLxQpbeV",
        "outputId": "f456e6af-8b7a-4b48-c4e6-2e40e5b2d253"
      },
      "source": [
        "#https://drive.google.com/file/d/1Xz4gXcpWjxhdl4l0P4fvQrIlCcd7NzC4/view?usp=sharing\n",
        "!gdown https://drive.google.com/uc?id=1Xz4gXcpWjxhdl4l0P4fvQrIlCcd7NzC4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Xz4gXcpWjxhdl4l0P4fvQrIlCcd7NzC4\n",
            "To: /content/latest.zip\n",
            "236MB [00:02, 91.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmoDhEpOpbhx",
        "outputId": "de85d821-1530-4090-f68d-85912e41e626"
      },
      "source": [
        "!unzip latest.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  latest.zip\n",
            "  inflating: latest/ckpt-3.data-00000-of-00001  \n",
            "  inflating: latest/ckpt-3.index     \n",
            "  inflating: latest/ckpt-4.index     \n",
            "  inflating: latest/ckpt-5.index     \n",
            "  inflating: latest/pipeline.config  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bzN-3LGngQZ"
      },
      "source": [
        "##**Setting up the Tensorflow Object Detection API Environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnVG7OmvsAOR",
        "outputId": "49e7b341-815f-4ac9-eddd-ea5a40c13b74"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.3 MB 12 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.37.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (5.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.39.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.6.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.34.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.5.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXYXAZuVW7_w",
        "outputId": "62d9c146-7086-4535-e80c-164657cdc978"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeyP0aYes9Zs",
        "outputId": "48a33497-4bce-4582-cde8-f133f472aa06"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEGpXLl3tQVX"
      },
      "source": [
        "## **Cloning TFOD 2.0 Github**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFkdXoEltLY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7836777-fbd0-4c18-9984-9dfa0e533295"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 61617, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 61617 (delta 3), reused 2 (delta 2), pack-reused 61613\u001b[K\n",
            "Receiving objects: 100% (61617/61617), 574.24 MiB | 29.30 MiB/s, done.\n",
            "Resolving deltas: 100% (42888/42888), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZwI0sTdtMsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26574c31-4c11-44f9-eb54-8c01d061ef3e"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NozH3MfAtMyR"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alOqL7ortM1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c3eab1-0def-4b56-e0ce-9809bc3f02a4"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 21.87 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XRlMiuEtM4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3b8b12-4237-4195-f248-cc3b5cf1091d"
      },
      "source": [
        "cd cocoapi/PythonAPI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ-xj6MUtM7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1e7a8a-e44c-4b65-9d1c-c5fae4611537"
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Qr7ACCtM_b"
      },
      "source": [
        "cp -r pycocotools /content/models/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLq79dR0uQFt"
      },
      "source": [
        "##**Install the Object Detection API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM2bgHvLtNFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b680a1-2934-4be5-bf78-14ade03a4c03"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZouxA5TuWgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f923445a-3c44-46d3-cb45-20e7796024f9"
      },
      "source": [
        "cd .. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q635Jl58uWjI"
      },
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyrPaXSxuWmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2d73a8-2828-4ae7-a550-89c6c29b140e"
      },
      "source": [
        "!python -m pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 90 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 39.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 43 kB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting tensorflow-text>=2.5.0\n",
            "  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.34.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.39.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.6.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 24.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 47.2 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 38.5 MB/s \n",
            "\u001b[?25hCollecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 923 kB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1665159 sha256=d25aab12f867ac4486e86287fd2f815669ef9184d7593718069d09b1a3b48088\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-12p7lbfi/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=0b2abcafec665b277927969547f1d27fd9c2a727e06b6874cea7d9d06263b91b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=0bcf6d96484c024e2aca2fe21e89519a4b1cbe3f76b79b1c420df092a23a3d06\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=5405e4334a199bfa039d6174fa5ddb116c0ba06c851a8288c89c7570476d095d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=e24b8550942f68ed3135842a763762136a84575c117e00c0ace7153d3f2979c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=2b728c3ad55b30705ae2259969bd106cd1cbb191aae83d1cfead9226c1c97c7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n",
            "Installing collected packages: requests, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.32.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 orjson-3.6.3 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjlR4lsmuWpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2a0749-571c-4a0c-b6bc-07022d271df0"
      },
      "source": [
        "# From within TensorFlow/models/research/\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-08 15:52:15.703279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:15.721759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:15.722635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "Running tests under Python 3.7.11: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-09-08 15:52:15.738226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:15.739068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:15.739949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:16.198167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:16.199004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:16.199823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 15:52:16.200536: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-09-08 15:52:16.200601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10699 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "W0908 15:52:16.543414 140602011568000 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.32s\n",
            "I0908 15:52:17.048655 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.68s\n",
            "I0908 15:52:17.727774 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "I0908 15:52:18.091294 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "I0908 15:52:18.416369 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0908 15:52:18.419020 140602011568000 mobilenet_v2.py:297] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.67s\n",
            "I0908 15:52:21.089864 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0908 15:52:21.090962 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0908 15:52:21.119048 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0908 15:52:21.137526 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0908 15:52:21.156175 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "I0908 15:52:21.278077 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "I0908 15:52:21.417524 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "I0908 15:52:21.567616 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "I0908 15:52:21.687330 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "I0908 15:52:21.802186 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0908 15:52:21.834891 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0908 15:52:22.212855 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0908 15:52:22.213047 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0908 15:52:22.213159 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0908 15:52:22.215608 140602011568000 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0908 15:52:22.235097 140602011568000 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0908 15:52:22.235246 140602011568000 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0908 15:52:22.302967 140602011568000 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0908 15:52:22.303170 140602011568000 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0908 15:52:22.486276 140602011568000 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0908 15:52:22.486478 140602011568000 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0908 15:52:22.665923 140602011568000 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0908 15:52:22.666128 140602011568000 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0908 15:52:22.953241 140602011568000 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0908 15:52:22.953446 140602011568000 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0908 15:52:23.250901 140602011568000 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0908 15:52:23.252362 140602011568000 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0908 15:52:23.622855 140602011568000 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0908 15:52:23.623062 140602011568000 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0908 15:52:23.714537 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0908 15:52:23.750266 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0908 15:52:23.824606 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0908 15:52:23.824816 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0908 15:52:23.824922 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0908 15:52:23.827062 140602011568000 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0908 15:52:23.845959 140602011568000 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0908 15:52:23.846088 140602011568000 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0908 15:52:23.994179 140602011568000 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0908 15:52:23.994422 140602011568000 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0908 15:52:24.281557 140602011568000 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0908 15:52:24.281800 140602011568000 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0908 15:52:24.561563 140602011568000 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0908 15:52:24.561794 140602011568000 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0908 15:52:24.927731 140602011568000 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0908 15:52:24.927948 140602011568000 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0908 15:52:25.299777 140602011568000 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0908 15:52:25.299982 140602011568000 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0908 15:52:25.789781 140602011568000 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0908 15:52:25.790010 140602011568000 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0908 15:52:25.974018 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0908 15:52:26.010123 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0908 15:52:26.229787 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0908 15:52:26.230013 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0908 15:52:26.230135 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0908 15:52:26.232254 140602011568000 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0908 15:52:26.251582 140602011568000 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0908 15:52:26.251729 140602011568000 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0908 15:52:26.400037 140602011568000 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0908 15:52:26.400276 140602011568000 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0908 15:52:26.702730 140602011568000 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0908 15:52:26.702954 140602011568000 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0908 15:52:26.995957 140602011568000 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0908 15:52:26.996159 140602011568000 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0908 15:52:27.380795 140602011568000 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0908 15:52:27.380998 140602011568000 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0908 15:52:27.753743 140602011568000 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0908 15:52:27.753959 140602011568000 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0908 15:52:28.233299 140602011568000 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0908 15:52:28.233495 140602011568000 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0908 15:52:28.416352 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0908 15:52:28.450567 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0908 15:52:28.541250 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0908 15:52:28.541491 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0908 15:52:28.541625 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0908 15:52:28.543951 140602011568000 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0908 15:52:28.565515 140602011568000 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0908 15:52:28.565659 140602011568000 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0908 15:52:28.717252 140602011568000 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0908 15:52:28.717472 140602011568000 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0908 15:52:29.010939 140602011568000 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0908 15:52:29.011176 140602011568000 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0908 15:52:29.309460 140602011568000 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0908 15:52:29.309658 140602011568000 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0908 15:52:29.794975 140602011568000 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0908 15:52:29.795185 140602011568000 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0908 15:52:30.269929 140602011568000 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0908 15:52:30.270190 140602011568000 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0908 15:52:30.848415 140602011568000 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0908 15:52:30.848622 140602011568000 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0908 15:52:31.036592 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0908 15:52:31.074963 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0908 15:52:31.403846 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0908 15:52:31.404067 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0908 15:52:31.404179 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0908 15:52:31.406267 140602011568000 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0908 15:52:31.425893 140602011568000 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0908 15:52:31.426025 140602011568000 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0908 15:52:31.585916 140602011568000 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0908 15:52:31.586156 140602011568000 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0908 15:52:31.965252 140602011568000 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0908 15:52:31.965453 140602011568000 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0908 15:52:32.350576 140602011568000 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0908 15:52:32.350819 140602011568000 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0908 15:52:32.914752 140602011568000 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0908 15:52:32.914982 140602011568000 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0908 15:52:33.491188 140602011568000 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0908 15:52:33.491419 140602011568000 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0908 15:52:34.220504 140602011568000 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0908 15:52:34.220724 140602011568000 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0908 15:52:34.416568 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0908 15:52:34.454616 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0908 15:52:34.552157 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0908 15:52:34.552339 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0908 15:52:34.552444 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0908 15:52:34.554291 140602011568000 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0908 15:52:34.571932 140602011568000 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0908 15:52:34.572055 140602011568000 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0908 15:52:34.786184 140602011568000 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0908 15:52:34.786383 140602011568000 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0908 15:52:35.254401 140602011568000 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0908 15:52:35.254621 140602011568000 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0908 15:52:35.727397 140602011568000 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0908 15:52:35.727592 140602011568000 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0908 15:52:36.391318 140602011568000 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0908 15:52:36.391514 140602011568000 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0908 15:52:37.321938 140602011568000 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0908 15:52:37.322240 140602011568000 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0908 15:52:38.188993 140602011568000 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0908 15:52:38.189209 140602011568000 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0908 15:52:38.482748 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0908 15:52:38.516389 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0908 15:52:38.622629 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0908 15:52:38.622827 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0908 15:52:38.622931 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0908 15:52:38.624988 140602011568000 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0908 15:52:38.643969 140602011568000 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0908 15:52:38.644099 140602011568000 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0908 15:52:38.866636 140602011568000 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0908 15:52:38.866841 140602011568000 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0908 15:52:39.419234 140602011568000 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0908 15:52:39.419438 140602011568000 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0908 15:52:39.995021 140602011568000 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0908 15:52:39.995271 140602011568000 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0908 15:52:40.749337 140602011568000 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0908 15:52:40.749543 140602011568000 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0908 15:52:41.489274 140602011568000 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0908 15:52:41.489519 140602011568000 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0908 15:52:42.739094 140602011568000 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0908 15:52:42.739326 140602011568000 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0908 15:52:43.025893 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0908 15:52:43.060544 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0908 15:52:43.187675 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0908 15:52:43.187934 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0908 15:52:43.188046 140602011568000 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0908 15:52:43.190323 140602011568000 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0908 15:52:43.210394 140602011568000 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0908 15:52:43.210549 140602011568000 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0908 15:52:43.521860 140602011568000 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0908 15:52:43.522091 140602011568000 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0908 15:52:44.150480 140602011568000 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0908 15:52:44.150669 140602011568000 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0908 15:52:44.806335 140602011568000 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0908 15:52:44.806876 140602011568000 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0908 15:52:45.757412 140602011568000 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0908 15:52:45.757629 140602011568000 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0908 15:52:46.714852 140602011568000 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0908 15:52:46.715058 140602011568000 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0908 15:52:47.933443 140602011568000 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0908 15:52:47.933654 140602011568000 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0908 15:52:48.604147 140602011568000 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0908 15:52:48.638809 140602011568000 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.95s\n",
            "I0908 15:52:48.786529 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.95s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0908 15:52:48.793902 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0908 15:52:48.796035 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0908 15:52:48.796717 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0908 15:52:48.798639 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0908 15:52:48.801134 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0908 15:52:48.802009 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0908 15:52:48.803570 140602011568000 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 33.076s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XQUHmKOobaz"
      },
      "source": [
        "#**Importing Model - ssd_resnet50_v1_fpn_640x640 from Tensorflow Model Zoo**\n",
        "Speed (ms)= 46\n",
        "COCO mAP= 34.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL4BBRoZuWr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6508a0af-72eb-4b22-ac3f-f852f10d1168"
      },
      "source": [
        "cd /content/content/training_demo/pre-trained-models "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/training_demo/pre-trained-models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MItGLVY3uWu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63242a33-e4f7-47bb-c938-70062da4024c"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-08 15:54:06--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.214.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.214.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244817203 (233M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet50_v1_fpn 100%[===================>] 233.48M   196MB/s    in 1.2s    \n",
            "\n",
            "2021-09-08 15:54:07 (196 MB/s) - ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [244817203/244817203]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzlPcDPLuWye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b415137-cc89-4f23-bf24-fcff28b35455"
      },
      "source": [
        "!tar -xvf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymsRwWzFpUIt"
      },
      "source": [
        "##**Generating .record files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFA0L4rmyGae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8826b80b-71f7-4e73-a9b7-aea9eb3a60e2"
      },
      "source": [
        "cd /content/content/training_demo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/training_demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU2lVZfzyuar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cecf43f-4d39-496f-b6aa-47529801f1b2"
      },
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/content/training_demo/images/train -l /content/content/training_demo/annotations/label_map.pbtxt -o /content/content/training_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/content/training_demo/images/test -l /content/content/training_demo/annotations/label_map.pbtxt -o /content/content/training_demo/annotations/test.record"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: /content/content/training_demo/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/content/training_demo/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1XR8O-GpigF"
      },
      "source": [
        "#**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNVwlSCq9pr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be34e0dc-0d65-4465-a973-a23c3a9a17a9"
      },
      "source": [
        "!python model_main_tf2.py --model_dir=/content/content/training_demo/models/my50 --pipeline_config_path=/content/content/training_demo/models/my50/pipeline.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-08 16:24:18.762077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:18.774440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:18.775321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:18.777002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:18.777876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:18.778710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:19.277953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:19.279428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:19.280183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 16:24:19.280891: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-09-08 16:24:19.280957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10699 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0908 16:24:19.286350 140695125718912 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0908 16:24:19.291737 140695125718912 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0908 16:24:19.292143 140695125718912 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0908 16:24:19.441833 140695125718912 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/content/training_demo/annotations/train.record']\n",
            "I0908 16:24:19.446639 140695125718912 dataset_builder.py:163] Reading unweighted datasets: ['/content/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/content/training_demo/annotations/train.record']\n",
            "I0908 16:24:19.446892 140695125718912 dataset_builder.py:80] Reading record datasets for input file: ['/content/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0908 16:24:19.447072 140695125718912 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0908 16:24:19.447229 140695125718912 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0908 16:24:19.450672 140695125718912 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0908 16:24:19.476446 140695125718912 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0908 16:24:28.144741 140695125718912 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0908 16:24:32.210041 140695125718912 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0908 16:24:34.398034 140695125718912 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-09-08 16:24:37.264883: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "2021-09-08 16:25:02.070254: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8004\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.703656 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.705197 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.708338 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.709647 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.712993 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.714248 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.717894 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.719156 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.721508 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0908 16:25:07.722690 140695125718912 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0908 16:25:08.898916 140691869406976 deprecation.py:548] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.885s\n",
            "I0908 16:28:16.811182 140695125718912 model_lib_v2.py:700] Step 100 per-step time 1.885s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1620437,\n",
            " 'Loss/localization_loss': 0.060152892,\n",
            " 'Loss/regularization_loss': 0.15831526,\n",
            " 'Loss/total_loss': 0.38051185,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0908 16:28:16.811661 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.1620437,\n",
            " 'Loss/localization_loss': 0.060152892,\n",
            " 'Loss/regularization_loss': 0.15831526,\n",
            " 'Loss/total_loss': 0.38051185,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 1.447s\n",
            "I0908 16:30:41.509547 140695125718912 model_lib_v2.py:700] Step 200 per-step time 1.447s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23636696,\n",
            " 'Loss/localization_loss': 0.1034183,\n",
            " 'Loss/regularization_loss': 0.15757032,\n",
            " 'Loss/total_loss': 0.49735558,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0908 16:30:41.509953 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.23636696,\n",
            " 'Loss/localization_loss': 0.1034183,\n",
            " 'Loss/regularization_loss': 0.15757032,\n",
            " 'Loss/total_loss': 0.49735558,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.448s\n",
            "I0908 16:33:06.335824 140695125718912 model_lib_v2.py:700] Step 300 per-step time 1.448s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09956426,\n",
            " 'Loss/localization_loss': 0.07780721,\n",
            " 'Loss/regularization_loss': 0.15679112,\n",
            " 'Loss/total_loss': 0.3341626,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0908 16:33:06.336213 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.09956426,\n",
            " 'Loss/localization_loss': 0.07780721,\n",
            " 'Loss/regularization_loss': 0.15679112,\n",
            " 'Loss/total_loss': 0.3341626,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.447s\n",
            "I0908 16:35:30.997023 140695125718912 model_lib_v2.py:700] Step 400 per-step time 1.447s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17873012,\n",
            " 'Loss/localization_loss': 0.03918494,\n",
            " 'Loss/regularization_loss': 0.15575074,\n",
            " 'Loss/total_loss': 0.3736658,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0908 16:35:30.997506 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.17873012,\n",
            " 'Loss/localization_loss': 0.03918494,\n",
            " 'Loss/regularization_loss': 0.15575074,\n",
            " 'Loss/total_loss': 0.3736658,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.445s\n",
            "I0908 16:37:55.525942 140695125718912 model_lib_v2.py:700] Step 500 per-step time 1.445s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13456094,\n",
            " 'Loss/localization_loss': 0.06950579,\n",
            " 'Loss/regularization_loss': 0.15502447,\n",
            " 'Loss/total_loss': 0.3590912,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0908 16:37:55.526383 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.13456094,\n",
            " 'Loss/localization_loss': 0.06950579,\n",
            " 'Loss/regularization_loss': 0.15502447,\n",
            " 'Loss/total_loss': 0.3590912,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 1.449s\n",
            "I0908 16:40:20.469037 140695125718912 model_lib_v2.py:700] Step 600 per-step time 1.449s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08432154,\n",
            " 'Loss/localization_loss': 0.04824539,\n",
            " 'Loss/regularization_loss': 0.15436079,\n",
            " 'Loss/total_loss': 0.2869277,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0908 16:40:20.469520 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.08432154,\n",
            " 'Loss/localization_loss': 0.04824539,\n",
            " 'Loss/regularization_loss': 0.15436079,\n",
            " 'Loss/total_loss': 0.2869277,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 1.451s\n",
            "I0908 16:42:45.522441 140695125718912 model_lib_v2.py:700] Step 700 per-step time 1.451s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10879509,\n",
            " 'Loss/localization_loss': 0.10133135,\n",
            " 'Loss/regularization_loss': 0.1532361,\n",
            " 'Loss/total_loss': 0.36336255,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0908 16:42:45.522852 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.10879509,\n",
            " 'Loss/localization_loss': 0.10133135,\n",
            " 'Loss/regularization_loss': 0.1532361,\n",
            " 'Loss/total_loss': 0.36336255,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 1.447s\n",
            "I0908 16:45:10.247138 140695125718912 model_lib_v2.py:700] Step 800 per-step time 1.447s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.062221084,\n",
            " 'Loss/localization_loss': 0.05180771,\n",
            " 'Loss/regularization_loss': 0.15191148,\n",
            " 'Loss/total_loss': 0.26594028,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0908 16:45:10.247626 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.062221084,\n",
            " 'Loss/localization_loss': 0.05180771,\n",
            " 'Loss/regularization_loss': 0.15191148,\n",
            " 'Loss/total_loss': 0.26594028,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 1.445s\n",
            "I0908 16:47:34.720237 140695125718912 model_lib_v2.py:700] Step 900 per-step time 1.445s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13244323,\n",
            " 'Loss/localization_loss': 0.09005212,\n",
            " 'Loss/regularization_loss': 0.1509105,\n",
            " 'Loss/total_loss': 0.37340584,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0908 16:47:34.720665 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.13244323,\n",
            " 'Loss/localization_loss': 0.09005212,\n",
            " 'Loss/regularization_loss': 0.1509105,\n",
            " 'Loss/total_loss': 0.37340584,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.445s\n",
            "I0908 16:49:59.243501 140695125718912 model_lib_v2.py:700] Step 1000 per-step time 1.445s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.067261815,\n",
            " 'Loss/localization_loss': 0.028833268,\n",
            " 'Loss/regularization_loss': 0.14976916,\n",
            " 'Loss/total_loss': 0.24586424,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0908 16:49:59.243944 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.067261815,\n",
            " 'Loss/localization_loss': 0.028833268,\n",
            " 'Loss/regularization_loss': 0.14976916,\n",
            " 'Loss/total_loss': 0.24586424,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.460s\n",
            "I0908 16:52:25.204346 140695125718912 model_lib_v2.py:700] Step 1100 per-step time 1.460s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08370775,\n",
            " 'Loss/localization_loss': 0.03687556,\n",
            " 'Loss/regularization_loss': 0.1485472,\n",
            " 'Loss/total_loss': 0.26913053,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0908 16:52:25.204784 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.08370775,\n",
            " 'Loss/localization_loss': 0.03687556,\n",
            " 'Loss/regularization_loss': 0.1485472,\n",
            " 'Loss/total_loss': 0.26913053,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.444s\n",
            "I0908 16:54:49.604537 140695125718912 model_lib_v2.py:700] Step 1200 per-step time 1.444s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11960188,\n",
            " 'Loss/localization_loss': 0.051070143,\n",
            " 'Loss/regularization_loss': 0.14730147,\n",
            " 'Loss/total_loss': 0.3179735,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0908 16:54:49.604918 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.11960188,\n",
            " 'Loss/localization_loss': 0.051070143,\n",
            " 'Loss/regularization_loss': 0.14730147,\n",
            " 'Loss/total_loss': 0.3179735,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.437s\n",
            "I0908 16:57:13.336251 140695125718912 model_lib_v2.py:700] Step 1300 per-step time 1.437s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09163382,\n",
            " 'Loss/localization_loss': 0.036916092,\n",
            " 'Loss/regularization_loss': 0.14603563,\n",
            " 'Loss/total_loss': 0.27458555,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0908 16:57:13.336689 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.09163382,\n",
            " 'Loss/localization_loss': 0.036916092,\n",
            " 'Loss/regularization_loss': 0.14603563,\n",
            " 'Loss/total_loss': 0.27458555,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.456s\n",
            "I0908 16:59:38.966403 140695125718912 model_lib_v2.py:700] Step 1400 per-step time 1.456s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0755497,\n",
            " 'Loss/localization_loss': 0.05805458,\n",
            " 'Loss/regularization_loss': 0.1450506,\n",
            " 'Loss/total_loss': 0.27865487,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0908 16:59:38.966832 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.0755497,\n",
            " 'Loss/localization_loss': 0.05805458,\n",
            " 'Loss/regularization_loss': 0.1450506,\n",
            " 'Loss/total_loss': 0.27865487,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.466s\n",
            "I0908 17:02:05.579461 140695125718912 model_lib_v2.py:700] Step 1500 per-step time 1.466s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09906881,\n",
            " 'Loss/localization_loss': 0.030854242,\n",
            " 'Loss/regularization_loss': 0.14381741,\n",
            " 'Loss/total_loss': 0.27374047,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0908 17:02:05.579878 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.09906881,\n",
            " 'Loss/localization_loss': 0.030854242,\n",
            " 'Loss/regularization_loss': 0.14381741,\n",
            " 'Loss/total_loss': 0.27374047,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.463s\n",
            "I0908 17:04:31.878521 140695125718912 model_lib_v2.py:700] Step 1600 per-step time 1.463s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10590386,\n",
            " 'Loss/localization_loss': 0.026226358,\n",
            " 'Loss/regularization_loss': 0.14237627,\n",
            " 'Loss/total_loss': 0.2745065,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0908 17:04:31.878883 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.10590386,\n",
            " 'Loss/localization_loss': 0.026226358,\n",
            " 'Loss/regularization_loss': 0.14237627,\n",
            " 'Loss/total_loss': 0.2745065,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.462s\n",
            "I0908 17:06:58.097739 140695125718912 model_lib_v2.py:700] Step 1700 per-step time 1.462s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11264402,\n",
            " 'Loss/localization_loss': 0.07291154,\n",
            " 'Loss/regularization_loss': 0.1416894,\n",
            " 'Loss/total_loss': 0.32724494,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0908 17:06:58.098140 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.11264402,\n",
            " 'Loss/localization_loss': 0.07291154,\n",
            " 'Loss/regularization_loss': 0.1416894,\n",
            " 'Loss/total_loss': 0.32724494,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.463s\n",
            "I0908 17:09:24.370200 140695125718912 model_lib_v2.py:700] Step 1800 per-step time 1.463s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06722698,\n",
            " 'Loss/localization_loss': 0.041011136,\n",
            " 'Loss/regularization_loss': 0.14130521,\n",
            " 'Loss/total_loss': 0.24954332,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0908 17:09:24.370658 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.06722698,\n",
            " 'Loss/localization_loss': 0.041011136,\n",
            " 'Loss/regularization_loss': 0.14130521,\n",
            " 'Loss/total_loss': 0.24954332,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.447s\n",
            "I0908 17:11:49.041604 140695125718912 model_lib_v2.py:700] Step 1900 per-step time 1.447s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06765687,\n",
            " 'Loss/localization_loss': 0.019296393,\n",
            " 'Loss/regularization_loss': 0.14024937,\n",
            " 'Loss/total_loss': 0.22720262,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0908 17:11:49.042019 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.06765687,\n",
            " 'Loss/localization_loss': 0.019296393,\n",
            " 'Loss/regularization_loss': 0.14024937,\n",
            " 'Loss/total_loss': 0.22720262,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.445s\n",
            "I0908 17:14:13.518234 140695125718912 model_lib_v2.py:700] Step 2000 per-step time 1.445s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13959181,\n",
            " 'Loss/localization_loss': 0.058750335,\n",
            " 'Loss/regularization_loss': 0.14029744,\n",
            " 'Loss/total_loss': 0.3386396,\n",
            " 'learning_rate': 0.04}\n",
            "I0908 17:14:13.518673 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.13959181,\n",
            " 'Loss/localization_loss': 0.058750335,\n",
            " 'Loss/regularization_loss': 0.14029744,\n",
            " 'Loss/total_loss': 0.3386396,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.457s\n",
            "I0908 17:16:39.270038 140695125718912 model_lib_v2.py:700] Step 2100 per-step time 1.457s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22712587,\n",
            " 'Loss/localization_loss': 0.08801133,\n",
            " 'Loss/regularization_loss': 0.1389876,\n",
            " 'Loss/total_loss': 0.4541248,\n",
            " 'learning_rate': 0.039984576}\n",
            "I0908 17:16:39.270498 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.22712587,\n",
            " 'Loss/localization_loss': 0.08801133,\n",
            " 'Loss/regularization_loss': 0.1389876,\n",
            " 'Loss/total_loss': 0.4541248,\n",
            " 'learning_rate': 0.039984576}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.448s\n",
            "I0908 17:19:04.044111 140695125718912 model_lib_v2.py:700] Step 2200 per-step time 1.448s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09965674,\n",
            " 'Loss/localization_loss': 0.10106474,\n",
            " 'Loss/regularization_loss': 0.13885553,\n",
            " 'Loss/total_loss': 0.33957702,\n",
            " 'learning_rate': 0.039938346}\n",
            "I0908 17:19:04.044492 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.09965674,\n",
            " 'Loss/localization_loss': 0.10106474,\n",
            " 'Loss/regularization_loss': 0.13885553,\n",
            " 'Loss/total_loss': 0.33957702,\n",
            " 'learning_rate': 0.039938346}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.445s\n",
            "I0908 17:21:28.585735 140695125718912 model_lib_v2.py:700] Step 2300 per-step time 1.445s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11523785,\n",
            " 'Loss/localization_loss': 0.09195997,\n",
            " 'Loss/regularization_loss': 0.13898635,\n",
            " 'Loss/total_loss': 0.34618416,\n",
            " 'learning_rate': 0.03986137}\n",
            "I0908 17:21:28.586164 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.11523785,\n",
            " 'Loss/localization_loss': 0.09195997,\n",
            " 'Loss/regularization_loss': 0.13898635,\n",
            " 'Loss/total_loss': 0.34618416,\n",
            " 'learning_rate': 0.03986137}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.445s\n",
            "I0908 17:23:53.077043 140695125718912 model_lib_v2.py:700] Step 2400 per-step time 1.445s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.118771605,\n",
            " 'Loss/localization_loss': 0.06255243,\n",
            " 'Loss/regularization_loss': 0.13788196,\n",
            " 'Loss/total_loss': 0.319206,\n",
            " 'learning_rate': 0.039753765}\n",
            "I0908 17:23:53.077436 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.118771605,\n",
            " 'Loss/localization_loss': 0.06255243,\n",
            " 'Loss/regularization_loss': 0.13788196,\n",
            " 'Loss/total_loss': 0.319206,\n",
            " 'learning_rate': 0.039753765}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.443s\n",
            "I0908 17:26:17.385826 140695125718912 model_lib_v2.py:700] Step 2500 per-step time 1.443s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0495853,\n",
            " 'Loss/localization_loss': 0.032649614,\n",
            " 'Loss/regularization_loss': 0.13709752,\n",
            " 'Loss/total_loss': 0.21933244,\n",
            " 'learning_rate': 0.039615706}\n",
            "I0908 17:26:17.386242 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.0495853,\n",
            " 'Loss/localization_loss': 0.032649614,\n",
            " 'Loss/regularization_loss': 0.13709752,\n",
            " 'Loss/total_loss': 0.21933244,\n",
            " 'learning_rate': 0.039615706}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.444s\n",
            "I0908 17:28:41.791012 140695125718912 model_lib_v2.py:700] Step 2600 per-step time 1.444s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06575593,\n",
            " 'Loss/localization_loss': 0.018402886,\n",
            " 'Loss/regularization_loss': 0.13496396,\n",
            " 'Loss/total_loss': 0.21912278,\n",
            " 'learning_rate': 0.039447397}\n",
            "I0908 17:28:41.791354 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.06575593,\n",
            " 'Loss/localization_loss': 0.018402886,\n",
            " 'Loss/regularization_loss': 0.13496396,\n",
            " 'Loss/total_loss': 0.21912278,\n",
            " 'learning_rate': 0.039447397}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.434s\n",
            "I0908 17:31:05.193289 140695125718912 model_lib_v2.py:700] Step 2700 per-step time 1.434s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.073215745,\n",
            " 'Loss/localization_loss': 0.030006323,\n",
            " 'Loss/regularization_loss': 0.13338554,\n",
            " 'Loss/total_loss': 0.23660761,\n",
            " 'learning_rate': 0.039249104}\n",
            "I0908 17:31:05.193649 140695125718912 model_lib_v2.py:701] {'Loss/classification_loss': 0.073215745,\n",
            " 'Loss/localization_loss': 0.030006323,\n",
            " 'Loss/regularization_loss': 0.13338554,\n",
            " 'Loss/total_loss': 0.23660761,\n",
            " 'learning_rate': 0.039249104}\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iVzPosbpwc5"
      },
      "source": [
        "##**Exporting the Trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlRqjT4AFOhv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0a3cc67-1ac6-49b9-8e0c-a8709d858e76"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/content/training_demo'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeI2URnR9zhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48680131-a9b4-4d40-ba16-f4f350e9e042"
      },
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/content/training_demo/models/my50/pipeline.config --trained_checkpoint_dir /content/content/training_demo/models/my50 --output_directory /content/content/training_demo/exported-models/mymodel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-08 17:33:44.728292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:44.738227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:44.738973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:44.748435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:44.749213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:44.749926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:45.225383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:45.226264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:45.227046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-09-08 17:33:45.227727: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-09-08 17:33:45.227836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10699 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0908 17:33:45.405910 139816459798400 deprecation.py:616] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2920324890>, because it is not built.\n",
            "W0908 17:34:05.700737 139816459798400 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f2920324890>, because it is not built.\n",
            "2021-09-08 17:34:18.845557: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0908 17:34:42.637407 139816459798400 save.py:254] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/content/training_demo/exported-models/mymodel/saved_model/assets\n",
            "I0908 17:34:49.410457 139816459798400 builder_impl.py:781] Assets written to: /content/content/training_demo/exported-models/mymodel/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/content/training_demo/exported-models/mymodel/pipeline.config\n",
            "I0908 17:34:50.288447 139816459798400 config_util.py:254] Writing pipeline config file to /content/content/training_demo/exported-models/mymodel/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4xMxLZzkzsU",
        "outputId": "f8800e46-2f6e-4f00-fe74-6369c2bc4696"
      },
      "source": [
        "!unzip /content/resized_our_photos.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/resized_our_photos.zip\n",
            "   creating: content/our_photos/resized/\n",
            "  inflating: content/our_photos/resized/prabh3.jpg  \n",
            "  inflating: content/our_photos/resized/mb1.jpg  \n",
            "  inflating: content/our_photos/resized/random2.jpg  \n",
            "  inflating: content/our_photos/resized/mb2.jpg  \n",
            "  inflating: content/our_photos/resized/mb3.jpg  \n",
            "  inflating: content/our_photos/resized/kp2.jpg  \n",
            "  inflating: content/our_photos/resized/kp1.jpg  \n",
            "  inflating: content/our_photos/resized/random1.jpg  \n",
            "   creating: content/our_photos/resized/.ipynb_checkpoints/\n",
            "  inflating: content/our_photos/resized/prabh1.jpg  \n",
            "  inflating: content/our_photos/resized/kp3.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIIKwpxtGAhK"
      },
      "source": [
        "#**Inferencing My Trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL33ttFoYS0j"
      },
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/content/our_photos/resized/mb2.jpg'\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/training_demo/exported-models/mymodel'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=1,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZuE9zf7yMOr"
      },
      "source": [
        "##**Resizing Image for Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hlvhhnzxx1O",
        "outputId": "0d7aa543-7e25-4b08-8c48-3e95db9c6ad7"
      },
      "source": [
        "import cv2 \n",
        "image=cv2.imread ('/content/our_photos/WhatsApp Image 2021-09-09 at 00.04.33.jpeg')\n",
        "r=150.0/image.shape[1]\n",
        "dim=(250, int (image.shape[0]*r))\n",
        "resize=cv2.resize(image,dim,interpolation=cv2.INTER_AREA)\n",
        "cv2.imwrite('prabh3.jpg',resize)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgilmEe22yp"
      },
      "source": [
        "##Downloading Exported Model\n",
        "(for future purpose)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0KheEfPGYhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7fd5db-a0ec-4c06-c56f-f0d7d371b9c2"
      },
      "source": [
        "!zip -r /content/final_model.zip /content/content/training_demo/exported-models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/content/training_demo/exported-models/ (stored 0%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/ (stored 0%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/checkpoint/ (stored 0%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/checkpoint/checkpoint (deflated 41%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/checkpoint/ckpt-0.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/checkpoint/ckpt-0.index (deflated 82%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/pipeline.config (deflated 69%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/saved_model/ (stored 0%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/saved_model/variables/ (stored 0%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/saved_model/variables/variables.index (deflated 80%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/saved_model/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/saved_model/saved_model.pb (deflated 93%)\n",
            "  adding: content/content/training_demo/exported-models/mymodel/saved_model/assets/ (stored 0%)\n",
            "  adding: content/content/training_demo/exported-models/.ipynb_checkpoints/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzz12xWi3ARD"
      },
      "source": [
        "##Downloading Resized Images\n",
        "(for future purpose)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bnVZaKb2hX0",
        "outputId": "8640f2f8-643b-4e67-bf64-d2899fbe532d"
      },
      "source": [
        "!zip -r /content/resized_our_photos.zip /content/our_photos/resized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/our_photos/resized/ (stored 0%)\n",
            "  adding: content/our_photos/resized/prabh3.jpg (deflated 1%)\n",
            "  adding: content/our_photos/resized/mb1.jpg (deflated 1%)\n",
            "  adding: content/our_photos/resized/random2.jpg (deflated 3%)\n",
            "  adding: content/our_photos/resized/mb2.jpg (deflated 1%)\n",
            "  adding: content/our_photos/resized/mb3.jpg (deflated 1%)\n",
            "  adding: content/our_photos/resized/kp2.jpg (deflated 2%)\n",
            "  adding: content/our_photos/resized/kp1.jpg (deflated 1%)\n",
            "  adding: content/our_photos/resized/random1.jpg (deflated 2%)\n",
            "  adding: content/our_photos/resized/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/our_photos/resized/prabh1.jpg (deflated 2%)\n",
            "  adding: content/our_photos/resized/kp3.jpg (deflated 1%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnEOn-HUp_d0"
      },
      "source": [
        "#**Script to Enable Webcam Integration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyNoec9ngio3"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S36VM_7LqHty"
      },
      "source": [
        "**Capture your Image using Webcam**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ldfvz1ygio4"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}